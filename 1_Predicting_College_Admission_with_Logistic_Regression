{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting College Admission Using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A researcher is interested in how variables, such as GRE (Graduate Record Exam scores), GPA (grade point average) and prestige of the undergraduate institution, effect admission into graduate school. The response variable, admit/donâ€™t admit, is a binary variable. Logistic Regression is a statistical technique capable of predicting a binary outcome. Using admission data from UCLA, we will try to identify which factors influence admission into graduate school."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "    - GPA\n",
    "    - GRE Score\n",
    "    - Rank (Undegraduate Prestige)\n",
    "\n",
    "This dataset has a binary response (outcome, dependent) variable called admit. There are three predictor variables: gre, gpa and rank. We will treat the variables gre and gpa as continuous. The variable rank takes on the values 1 through 4. Institutions with a rank of 1 have the highest prestige, while those with a rank of 4 have the lowest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal: Identify various factors that may influence admission into graduate school."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexcheng/miniconda3/lib/python3.6/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import pylab as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/binary.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['admit', 'gre', 'gpa', 'prestige'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rename 'rank' to 'prestige'\n",
    "df.columns = ['admit', 'gre', 'gpa', 'prestige']\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>587.700000</td>\n",
       "      <td>3.389900</td>\n",
       "      <td>2.48500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.516536</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.94446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.395000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre         gpa   prestige\n",
       "count  400.000000  400.000000  400.000000  400.00000\n",
       "mean     0.317500  587.700000    3.389900    2.48500\n",
       "std      0.466087  115.516536    0.380567    0.94446\n",
       "min      0.000000  220.000000    2.260000    1.00000\n",
       "25%      0.000000  520.000000    3.130000    2.00000\n",
       "50%      0.000000  580.000000    3.395000    2.00000\n",
       "75%      1.000000  660.000000    3.670000    3.00000\n",
       "max      1.000000  800.000000    4.000000    4.00000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admit         0.466087\n",
      "gre         115.516536\n",
      "gpa           0.380567\n",
      "prestige      0.944460\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check out standard deviations\n",
    "print(df.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prestige   1   2   3   4\n",
      "admit                   \n",
      "0         28  97  93  55\n",
      "1         33  54  28  12\n"
     ]
    }
   ],
   "source": [
    "# Check out admittance to graduate school by prestige of undergraduate\n",
    "print(pd.crosstab(df['admit'], df['prestige'], rownames=['admit']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x10ea5b278>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x111e303c8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x111e57630>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x111ef5208>]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAG+hJREFUeJzt3XuQXOV55/HvSEJSwIMswgBxhaB4bf+CHW4RBgwItJh7\njOXCm7jKBTYW1yxesMHLVVrvOmKBWAKvbGOckWVhKpSzQBRAlIxS3IwwLmwZHBTDo4jFcTY22TER\nIEUgkJj94z1tNaOenp6ennNOn/l9qlTqPqf79NNn3n767fd2egYHBzEzs2qYVHQAZmbWOU7qZmYV\n4qRuZlYhTupmZhXipG5mViFO6mZmFTKl6ADs7SStAu6KiBWjeM7TwFxgEFgZESeMT3RmVnZO6hUQ\nEYcCSJoFHFFsNGZWJCf1nEiaBNwMHAX0Aj3AecALwG3Au4B/Avape87r2XM+AuwJ/FfgT4CDgF8C\nZ0TEv0saBPqAbwO/ldXcZ0fEjnzenVnrJF0FnAtsBr4PfAx4hPRL80BSWV4DXBIRb0qaD1wITAX2\nAm6IiG8UEHpXcJt6fo4kJe4PRcT7SYn8KuDrwA8j4gPAJcAf1D1nGvCriDgIuAVYBnwOeD8wA5g3\n5DU+A7wWEYc6oVsZSToFOAf4IDCbVMGpOQQ4kVS+3w9cKOkdwPnA6RFxGPAJ4C/yjLnbOKnnJCKe\nABaQCupi4D8B7yAV4hXZYzYCDw156t3Z/88Dz0TEv0TEW6Qa/l45hG7WSacDd0bEyxExSKrU1KyI\niC0RsQ34DnBKRGwh/VL9Y0l/DlxL+tzYMJzUcyLpj4H7s7v3ALeSmmAGs/9rtg956ra622+OW4Bm\n+djO28v7jiH7aiYBOyT9LvA0cACwllQxsiac1PNzEnBf1hb4I1I74mTge8AFAJJ+D/iPY3iN7cBk\nST0jPtKsGPcDH5c0I7t/LqliA/AJSdMkTQc+DdwHHA4MAIsi4gFSrR1Jk/MNu3s4qefnVuB4SX8P\nPEFqTvl94L8A75f0LPAtUq2kXb8CfgI8K+m3xxivWcdFxENAP/CEpB+T+oa2Zru3Ao8Bz2T/f5vU\nYfp/gZD0FPB7pCT/npxD7xo9XnrXzPIi6XDg6IhYmt2/jDSI4DVgfUQsLjK+KnBN3czytAGYI2m9\npGeADwOXFRxTpbimbtYCSbuRhqHOInXunU/qw1hBahNeD1ycjUwyK4xr6matOR2YEhFHA18CrgNu\nAhZExBzSiI6h8wbMcuekbtaaDcCUbGbwnqThpbOBR7P9q0lzDswKVegyAQMDm4dt+5k5c3c2bdo6\n3O4Jw+chaXYe+vp68xjCuYXU9PIcsDdpaN1x2QQaSFPeZzR+6k7bt+8YnDLFo/FszIYt86Vd+8UF\nP/F5SEpwHj4PPBARV0vanzTzd2rd/l7g5ZEOkscXdF9fLwMDm8f9dUbLcY1Os7j6+nobbgc3v5i1\nahPwSnb734DdgKckzc22nUYaW21WqNLW1M1K5mZguaTHSDX0a4AfA/2SpgLPAncVGJ8Z4KRu1pJs\nYak/bbDr+LxjMWumtEn9jMvvGfVzll/lC/6YTUTzbxi6uGlrqpgz3KZuZlYhTupmZhXipG5mViFO\n6mZmFeKkbmZWIU7qZmYV4qRuZlYhTupmZhXipG5mViFO6mZmFeKkbmZWIaVd+8XMbLy1s2ZM2deL\ncU3dzKxCnNTNzCrEzS9mZuOsnWae+5bMa+u1nNTNWiTpauCjpCsf3QI8CqwABoH1wMUR8VZhAZrh\n5hezlmTXIj0aOIZ0taP9gZuABRExh3R19/aqVmYd5KRu1ppTgGeAlcB9wCpgNqm2DrAaOLGY0Mx2\ncvOLWWv2Bg4APgL8PnAvMCkiBrP9m4EZIx1k5szdmTJl8rgFWdPX1zvur9GOssY1Gnm+h3Zey0nd\nrDUvAc9FxBtASHqd1ART0wu8PNJBNm3aOk7h7dTX18vAwOZxf53RKmtco5XnexjutZol+6ZJXdJu\nwHJgFjANWAT8jAadQ5LOBy4EtgOLImLVaN+AWYmtBS6VdBPwO8AewIOS5kbEI8BpwMMFxmcGjFxT\nPwt4KSLOlrQX8HT2b0FEPCLpVmCepCeAS4DDgenAWkl/FxHbxjN4s7xExCpJxwFPkvqiLgZeAPol\nTQWeBe4qMMTKaGf4n+00UlK/k50FtYdUCx/aOXQysAN4PEvi2yRtBA4GftTxiM0KEhFXNNh8fO6B\nmDXRNKlHxBYASb2k5L4AWNygc2hP4JW6pxbSaVSFTphGqvq+RsvnwWxkI3aUStqfNIzrloi4Q9Jf\n1O2udQ69mt0eur2pTncaVaETZqiqdC6NVbPz4GRvtlPTceqS9gXWAFdGxPJs81PZRAxInUOPkdoZ\n50iaLmkGcCCpE9XMzHI0Uk39GmAmsFDSwmzbpcDS+s6hiNghaSkpwU8Cro2I18craDMza2ykNvVL\nSUl8qF06hyKiH+jvUFxmZtYGLxNgZlYhTupmZhXipG5mViFO6mZmFeKkbmZWIU7qZmYV4qRuZlYh\nTupmZhXipG5mViFO6mZmFeKkbmZWIb5GqdkoSNoHWAecRLpozAqGXNqxuOjKx1cxyp9r6mYtyq7Z\n+03gtWzTTaRLO84hXRlsXlGxmdU4qZu1bjFwK/DL7P7QSzueWERQZvXc/GLWAknnAAMR8YCkq7PN\nPQ0u7dhUpy/hOBxfDWr85Hlu23ktJ3Wz1swHBiWdCBwKfAfYp25/IZdwbMSXQBxfZ1x+T26v1c4l\nHN38YtaCiDguIo6PiLnA08CngNUNLu1oVijX1M3adznQX39px4LjMXNSNxutrLZes8ulHc2K5KRu\nuWtn7PJ9Szxa0KwVblM3M6sQ19TNrCWeHdodXFM3M6sQJ3UzswpxUjczq5CW2tQlHQncGBFzJb2H\nBivTSTofuJC0ct2iiFg1TjGbmdkwRqypS7oCWAZMzzbtsjKdpP2AS4BjgFOA6yVNG5+QzcxsOK00\nvzwPnFl3v9HKdEcAj0fEtoh4BdgIHNzJQM3MbGQjNr9ExN2SZtVtarQy3Z7AK3WPKWTFuqquTFfV\n9zVaPg9mI2tnnHr9lV1qK9O9mt0eur2pTq9YV8WV6bzi3k7trFhnNtG0M/rlqQYr0z0JzJE0XdIM\n4EBSJ6qZmeWonZr6LivTRcQOSUtJCX4ScG1EvN7BOM3MrAUtJfWI+DlwVHZ7Aw1WpouIfqC/k8GZ\nmdnoePKRmVmFOKmbmVWIV2k0a4Gk3YDlwCxgGrAI+BkNZlcXFKIZ4Jq6WavOAl7KZlKfCnyNBrOr\nC4zPDHBN3axVd7LzGqQ9pDWOhs6uPhlY2ewgnZ5wNxyP3a+Gdv6OTupmLYiILQCSeknJfQGwuMHs\n6qY6PeGuEU9Yq452Jty5+cWsRZL2Bx4Gbo+IO2g8u9qsUE7qZi2QtC+wBrgyIpZnmxvNrjYrlJtf\nzFpzDTATWChpYbbtUmBp/ezqooIzq3FSN2tBRFxKSuJD7TK7uux8Aelqc/OLmVmFOKmbmVWIk7qZ\nWYU4qZuZVYiTuplZhTipm5lViJO6mVmFOKmbmVWIk7qZWYU4qZuZVYiTuplZhTipm5lViJO6mVmF\neJVGsy7mFRdtKCd1s5JwgrZO6GhSlzQJuAU4BNgGnBcRGzv5GmZl4jJvZdPpNvWPAdMj4kPAVcCS\nDh/frGxc5q1UOp3UjwW+BxARPwQO7/DxzcrGZd5KpWdwcLBjB5O0DLg7IlZn938BvDsitnfsRcxK\nxGXeyqbTNfVXgd7647twW8W5zFupdDqpPw6cDiDpKOCZDh/frGxc5q1UOj2kcSVwkqQfAD3AZzp8\nfLOycZm3Uulom7qZmRXLywSYmVWIk7qZWYU4qZuZVUiha7+MNMVa0hnAfwO2A8sjor+QQMdZC+fh\n88B5wEC26cKIiNwDzYmkI4EbI2LukO0Tojy0QtJuwHJgFjANWBQR99btL6zMSJoM9AMCBoGLImJ9\n3f5C/o4txFXkOdsHWAecFBHP1W0f9bkqekGv30yxzoaDLQHmwW8K7c3AB4F/Bx6XdG9E/Gth0Y6f\nYc9DZjbwqYhYV0h0OZJ0BXA26W9ev30ilYdWnAW8FBFnS9oLeBq4t25/kWXmDICIOEbSXOA6yvG5\nHjauTCHnLDsn3wRea7B91Oeq6OaXZlOsDwQ2RsSmiHgDWAscl3+IuRhpqvls4GpJayVdnXdwOXse\nOLPB9olUHlpxJ7Awu91DqsnVK6zMRMTfAhdkdw8AXq7bXdjfcYS4oLhzthi4FfjlkO1tnauik/qe\nwCt193dImjLMvs3AjLwCy1mz8wDwXeAi4ATgWEkfyTO4PEXE3cCbDXZNpPIwoojYEhGbJfUCdwEL\nhjyk0DITEdsl3QZ8Ffirul2F/h2bxAUFnDNJ5wADEfFAg91tnauik3qzKdZD9/Wy6zdrVQx7HiT1\nAF+JiF9n39b3A4cVEGPRJlJ5aImk/YGHgdsj4o667aUoMxHxaeB9QL+kPbLNhf8dG8VV4DmbT5q8\n9ghwKPAdSftl+9o6V0W3qT9Oauf63w2mWD8LvDdrL9xC+tmxOP8Qc9HsPOwJrJd0IKld7QRSB9lE\nM5HKw4gk7QusAT4bEQ8O2V1omZF0NvC7EXE9sBV4K/sHBf4dR4irkHMWEb9pTskS+0UR8WK2qa1z\nVeiM0rpRHwezc4r1HwHviIi/rOv5nUTq+f16YcGOoxbOw9nAJaSRMQ9GxBcLCzYHkmYB342IoyR9\nkglWHloh6X8BnwCeq9vcD+xRdJnJar/fBvYDdgNuAPag4L9jC3EV+jmrJXXGmAO9TICZlZKk84Cp\nEXGLpIuAd0bEDUXHVXZFN7+YmQ3nWGA9QETcWnAsXcM19RKQdBVwLql3+/ukceuPAHsB/wFYRRq+\ndiNwPDAZeAq4JCJeLSBkMwCy8d5fBv4FeDdprPU5wJW0WH4l/Rmp2eEN4HXgQtIEoW9lx/ufQB+w\nd0R8VtIRpObKqaQhsAcAl0XEI1lzxYJs31bgCxHxxPiehXIpevTLhCfpFNKH4IOkcbL1vd27R8QH\nIuJK0vUvtwOzI+IQ0phW/xS1MvgjYElEHExqs7492z5i+c1meX4FODUiPgj8JXBsRKwkTaa6ub4d\nORvqezewMHu9paRRI0h6L+kL4PSIOIw0Jv1v6kbeTAhufine6cCdEfEygKSvAx/O9q2te9xHgHeS\nhj9Bqon8vxzjNBvOTyPisez2cuDrwK9oofxGxA5JdwI/kHQ/aUTPHQzvIIDa5QMj4mFJtan+JwG/\nAzyYvQak0S3vAX46pnfYRZzUi7edNOKlZkfd7S11tycDl9ZdC/MdwPTxD89sRPWzWXuyfztosfxG\nxFmS/hA4kdRscy5vn74/9LV6hmyrfWYmk0atfKK2IxvLP3SmZqW5+aV49wMfl1SbKXYuabGhoR4A\nPitpajYEsh+4PqcYzZo5VNLB2e0LSPMuhk6SaVh+Je0t6Z9J69h8hdQefkj2nO2koYf1ngW2SToV\nIGtfP4j0mXkIOFnSH2T7Tgf+nglW+XFSL1hEPEQq4E9I+jFpGvDWBg/9c+DnpA6mn5FqK5fnFKZZ\nMy8C10l6htTJf3aDxzQsvxHxa2ARqclkHamf6LzsOauBS+rXYclmWn8c+O+SniJ9Bl4EtkbEP5C+\nVL4r6afZa340It62OFzVefRLwSQdDhwdEUuz+5cBR9b/hDQrq2z0y9ci4g9zfM0vA4sj4l+z5pWf\nAu+u9UtNdG5TL94G4EpJF5B+Qv6CnSvJmdmu/olUs3+TVOM/zwl9J9fUzcwqxG3qZmYV4qRuZlYh\nhbapDwxsHgSYOXN3Nm1qNOCj3Lox7m6MGZrH3dfXO3TccmnVynwj3fa3cbzjq90yX4qa+pQpk4sO\noS3dGHc3xgzdG/dodNt7dLzjq914S5HUzcysMzyk0WwYko4EboyIuZIOI602+I/Z7m9ExF9LOp+0\nquB2YFFErCooXDPASd2sIUlXkGZG1mYjzgZuiogldY/Zj3SlnMNJU9HXSvq7iNiWd7xmNU7qFTT/\nhodG/ZzlV50wDpF0teeBM9m5jOxsQJLmkWrrnwOOAB7Pkvg2SRtJlyT80XAHnTlz96ZtpX19vcPu\nK9oZl98z6ufct2S4dbmKUebz20g78TqpmzUQEXdn10qteRJYFhHrJF0LfBF4Gnil7jGbSWv3DKvZ\n6Iu+vl4GBja3HXMZlen9dNv5bRZvs2TvjlKz1qyMiHW128BhwKu8/aImvey6OqFZrpzUzVrzQLbM\nK6SLmKwj1d7nSJqeLZ18INk1Nc2K4uYXs9b8GfDVbBGpF4ELsutrLgUeI1WQro2I14sM0qytpC7p\nHNJ1NSH1+h8KfIgGQ77GGJ9ZYSLi58BR2e2fAMc0eEw/aT18s1JoK6lHxApgBfzmmprLaTDky8zM\n8jWm5pfsAg8fiIiLJX2DIUO+IqJpV3P98K5uG2pUM95xtzOMrB3dcP67IUazoo21Tf0a4H9ktxsN\n+fpCsyfXhnd121Cjmm6Nu5Gyv492h3eZTTRtj36R9E5AEfFwtqnRkC8zM8vRWIY0Hgc8WHe/0ZAv\nMzPL0ViaXwT8n7r7uwz5GktgZmY2em0n9Yj48pD7DYd8mZlZfjyj1MysQpzUzcwqxEndzKxCnNTN\nzCrESd3MrEK8SqMB7V0tCXzFJCsHl9+dXFM3M6sQJ3UzswpxUjczqxAndTOzCnFSNzOrECd1M7MK\ncVI3M6sQJ3UzswpxUjczqxDPKDUbhqQjgRsjYq6k9wArgEFgPXBxRLwl6XzgQmA7sCgiVhUWsBmu\nqZs1JOkKYBkwPdt0E7AgIuYAPcA8SfsBl5AuDnMKcL2kaUXEa1bjmrpZY88DZwK3Z/dnA49mt1cD\nJwM7gMcjYhuwTdJG4GDgR8MddObM3ZkyZfKwL9rX1zv2yEuk7O+nivE5qZs1EBF3S5pVt6knIgaz\n25uBGcCewCt1j6ltH9amTVuH3dfX18vAwOa24i2rsr+fMsfXrDw0S/ZtJ3VJPwFeze6+AFxHgzbH\ndo9vVjL1ZbkXeJlU/nsbbDcrTFtt6pKmk2ouc7N/n6FBm2MH4zQr2lOS5ma3TwMeA54E5kiaLmkG\ncCCpQmNWmHZr6ocAu0takx3jGhq3Oa4cc4QV0u6az1YKlwP9kqYCzwJ3RcQOSUtJCX4ScG1EvF5k\nkGbtJvWtwGLS6ID3kpJ4ozbHpuo7jcreYTGcbo27U/J8/3mf64j4OXBUdnsDcHyDx/QD/bkGZtZE\nu0l9A7AxS+IbJL1EqqnXtNS2WOs06tYOom6Nu5Pyev/tdhqZTTTtjlOfDywBkPQu0iiANQ3aHM3M\nLEft1tS/BayQtJY02mU+8GuGtDl2JkQzM2tVW0k9It4APtlg1y5tjmZmlh8vE2BmViGeUWpj0s4w\nzeVXnTAOkZgZuKZuZlYpTupmZhXipG5mViFO6mZmFeKkbmZWIU7qZmYV4qRuZlYhTupmZhXiyUdm\nZuOsnUl69y1p7zpDTuqWuzwLuNlE4+YXM7MKcU3drCTOuPyeUT/H6+jYUK6pm5lViJO6mVmFOKmb\nmVWI29TNWiTpJ8Cr2d0XgOuAFaRLOq4HLo6It4qJzixxUjdrgaTpQE9EzK3bdi+wICIekXQrMA9Y\nWVCIZoCTelvaGWdtXe8QYHdJa0ifm2uA2cCj2f7VwMk4qVvB2krqknYDlgOzgGnAIuCfgVXAP2YP\n+0ZE/HUHYjQrg63AYmAZ8F5SEu+JiMFs/2ZgxkgHmTlzd6ZMmdyxoPr6ejt2rPHg+Mamnfjaramf\nBbwUEWdL2gt4GvgScFNELGnzmGZltgHYmCXxDZJeItXUa3qBl0c6yKZNWzsa1MDA5o4er9Mc39gM\nF1+zZN9uUr8TuCu73QNsJxVwSZpHqq1/LiKanrH6WkvZvzGteAWXkfnAQcB/lvQuYE9gjaS5EfEI\ncBrwcIHxmQFtJvWI2AIgqZeU3BeQmmGWRcQ6SdcCXwS+0Ow4tVpLX19v6b8xrXjt1Fo66FvACklr\nSaNd5gO/BvolTQWeZWdFx6wwbXeUStqf1Cl0S0TcIemdEVH7+bkS+GonAjQrg4h4A/hkg13H5x2L\nWTNtTT6StC+wBrgyIpZnmx+QdER2+8PAug7EZ2Zmo9BuTf0aYCawUNLCbNtlwM2S3gReBC7oQHxm\nZjYK7bapXwpc2mDXMWMLx8zMxsJrv5iZVYiTuplZhTipm5lViJO6mVmFTPgFvbw4l5lViWvqZmYV\n4qRuZlYhTupmZhXipG5mViFO6mZmFeKkbmZWIU7qZmYV4qRuZlYhTupmZhXipG5mViFO6mZmFeKk\nbmZWIU7qZmYV4qRuZlYhHV16V9Ik4BbgEGAbcF5EbOzkazTjZXQtb0WXebOhOl1T/xgwPSI+BFwF\nLOnw8c3KxmXeSqXTF8k4FvgeQET8UNLh7R7ItW7rEh0r82ad0DM4ONixg0laBtwdEauz+78A3h0R\n2zv2ImYl4jJvZdPp5pdXgd7647twW8W5zFupdDqpPw6cDiDpKOCZDh/frGxc5q1UOt2mvhI4SdIP\ngB7gMx0+vlnZuMxbqXS0Td3MzIrlyUdmZhXipG5mViFO6mZmFdLpjtKGJO0GLAdmAdOARcDPgBXA\nILAeuDgi3pJ0PnAhsB1YFBGr8ohxOJL2AdYBJ2UxraD8MV8NfBSYSprC/igljzsrI7eRysgO4Hy6\n5Hx3gqQjgRsjYm7RsYyk0ec5Iu4tNKgmJE0G+gGRytJFEbG+2KhGVp97IuK5Vp+XV039LOCliJgD\nnAp8DbgJWJBt6wHmSdoPuAQ4BjgFuF7StJxi3EVWeL8JvJZt6oaY5wJHZ/EcD+xPF8RNGhY4JSKO\nBr4EXEd3xD1mkq4AlgHTi46lRY0+z2V2BkBEHAMsIJWtUmuQe1qWV1K/E1iY3e4h1bBmk2qQAKuB\nE4EjgMcjYltEvAJsBA7OKcZGFgO3Ar/M7ndDzKeQxkqvBO4DVtEdcW8ApmQLZO0JvEl3xN0JzwNn\nFh3EKDT6PJdWRPwtcEF29wDg5QLDadXQ3NOyXJJ6RGyJiM2SeoG7SN+WPRFRG0+5GZhB+jC/UvfU\n2vbcSToHGIiIB+o2lzrmzN7A4cCfABcBf0Wa5Vj2uLeQfs4/R/qpvJTuON9jFhF3k77EusIwn+dS\ni4jtkm4Dvkr6TJTWMLmnZbl1lEraH3gYuD0i7gDeqtvdS/r2HDrlura9CPNJk0oeAQ4FvgPsU7e/\njDEDvAQ8EBFvREQAr/P2pFfWuD9Pivt9pGVsbyP1CdSUNe4JqcHnufQi4tPA+4B+SXsUHU8Tu+Se\nrNmxJbkkdUn7AmuAKyNiebb5qaz9F+A04DHgSWCOpOmSZgAHkjrIchcRx0XE8VnH1dPAp4DVZY45\nsxY4VVKPpHcBewAPdkHcm9hZA/83YDdKXkYmqmE+z6Ul6exs8ADAVlKF8q0mTylUo9wTES+2+vxc\nRr8A1wAzgYWSam1xlwJLJU0FngXuiogdkpaSPryTgGsj4vWcYmzF5aRv+dLGHBGrJB1HSn6TgIuB\nF8oeN3AzsFzSY6Qa+jXAjyl/3BNRo8/zaREx6k69nPwN8G1J3ydVFj5X4ljHzMsEmJlViCcfmZlV\niJO6mVmFOKmbmVWIk7qZWYU4qZuZVYiTuplZhTipm5lVyP8H92xTtompH/4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ea5b208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prestige_1  prestige_2  prestige_3  prestige_4\n",
      "0           0           0           1           0\n",
      "1           0           0           1           0\n",
      "2           1           0           0           0\n",
      "3           0           0           0           1\n",
      "4           0           0           0           1\n"
     ]
    }
   ],
   "source": [
    "# get_dummies for 'prestige'\n",
    "dummy_prestige = pd.get_dummies(df['prestige'], prefix='prestige')\n",
    "print(dummy_prestige.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit  gre   gpa  prestige_2  prestige_3  prestige_4\n",
      "0      0  380  3.61           0           1           0\n",
      "1      1  660  3.67           0           1           0\n",
      "2      1  800  4.00           0           0           0\n",
      "3      1  640  3.19           0           0           1\n",
      "4      0  520  2.93           0           0           1\n"
     ]
    }
   ],
   "source": [
    "# create a clean dataframe for regression\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "data = df[cols_to_keep].join(dummy_prestige.ix[:, 'prestige_2':])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['intercept'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "cols_to_keep = data.columns[1:]\n",
    "\n",
    "X = data[cols_to_keep]\n",
    "y = data['admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573147\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# Perform the logistic regression\n",
    "logit = sm.Logit(y, X)\n",
    "\n",
    "# Fit the model\n",
    "result = logit.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   No. Observations:                  400\n",
      "Model:                          Logit   Df Residuals:                      394\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Thu, 13 Apr 2017   Pseudo R-squ.:                 0.08292\n",
      "Time:                        13:51:33   Log-Likelihood:                -229.26\n",
      "converged:                       True   LL-Null:                       -249.99\n",
      "                                        LLR p-value:                 7.578e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "gre            0.0023      0.001      2.070      0.038       0.000       0.004\n",
      "gpa            0.8040      0.332      2.423      0.015       0.154       1.454\n",
      "prestige_2    -0.6754      0.316     -2.134      0.033      -1.296      -0.055\n",
      "prestige_3    -1.3402      0.345     -3.881      0.000      -2.017      -0.663\n",
      "prestige_4    -1.5515      0.418     -3.713      0.000      -2.370      -0.733\n",
      "intercept     -3.9900      1.140     -3.500      0.000      -6.224      -1.756\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# See the results\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0         1\n",
      "gre         0.000120  0.004409\n",
      "gpa         0.153684  1.454391\n",
      "prestige_2 -1.295751 -0.055135\n",
      "prestige_3 -2.016992 -0.663416\n",
      "prestige_4 -2.370399 -0.732529\n",
      "intercept  -6.224242 -1.755716\n"
     ]
    }
   ],
   "source": [
    "# Check out the confidence intervals\n",
    "print(result.conf_int())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Odds Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the exponential of each of the coefficients to generate the odds ratios. This tells you how a 1 unit increase or decrease in a variable affects the odds of being admitted. For example, we can expect the odds of being admitted to decrease by about 50% if the prestige of a school is 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gre           1.002267\n",
      "gpa           2.234545\n",
      "prestige_2    0.508931\n",
      "prestige_3    0.261792\n",
      "prestige_4    0.211938\n",
      "intercept     0.018500\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(np.exp(result.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                2.5%     97.5%        OR\n",
      "gre         1.000120  1.004418  1.002267\n",
      "gpa         1.166122  4.281877  2.234545\n",
      "prestige_2  0.273692  0.946358  0.508931\n",
      "prestige_3  0.133055  0.515089  0.261792\n",
      "prestige_4  0.093443  0.480692  0.211938\n",
      "intercept   0.001981  0.172783  0.018500\n"
     ]
    }
   ],
   "source": [
    "# odds ratios and 95% CI\n",
    "params = result.params\n",
    "conf = result.conf_int()\n",
    "conf['OR'] = params\n",
    "conf.columns = ['2.5%', '97.5%', 'OR']\n",
    "print(np.exp(conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are confident that there is an inverse relationship between the probability of being admitted and the prestige of  a candidate's undergraduate school. The probability of being accepted into a graduate program is higher for students who attended a top ranked undergraduate college (`prestige_1==True`) as opposed to a lower ranked school with, say, `prestige_4==True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
